# AdaptiveInterviewer v2.0: Refactored v·ªõi Clean Architecture
import datetime
import hashlib
import re
import json
from dataclasses import dataclass, asdict, field
from typing import List, Dict, Optional, Callable
from enum import Enum
from pymongo import MongoClient
from bson import ObjectId
import html


from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAI
from langchain_huggingface import HuggingFaceEmbeddings
from GetApikey import loadapi


# =======================
# 1. Enums & Data Classes
# =======================

class Level(Enum):
    YEU = "yeu"
    TRUNG_BINH = "trung_binh"
    KHA = "kha"
    GIOI = "gioi"
    XUAT_SAC = "xuat_sac"


class QuestionDifficulty(Enum):
    VERY_EASY = "very_easy"
    EASY = "easy"
    MEDIUM = "medium"
    HARD = "hard"
    VERY_HARD = "very_hard"

class InterviewPhase(Enum):
    WARMUP = "warmup"          # Gi·ªõi thi·ªáu, l√†m quen
    TECHNICAL = "technical"     # Ph·ªèng v·∫•n chuy√™n m√¥n
    CLOSING = "closing"         # K·∫øt th√∫c

@dataclass
class QuestionAttempt:
    question: str
    answer: str
    score: float
    analysis: str
    difficulty: QuestionDifficulty
    timestamp: str
    question_hash: Optional[str] = None



@dataclass
class InterviewConfig:
    """Configurable interview parameters"""
    threshold_high: float = 7.0
    threshold_low: float = 4.0
    max_attempts_per_level: int = 2
    max_total_questions: int = 8
    max_upper_level: int = 2
    llm_temperature: float = 0.5
    max_memory_turns: int = 6

    difficulty_map: Dict[Level, List[QuestionDifficulty]] = field(default_factory=lambda: {
        Level.YEU: [QuestionDifficulty.VERY_EASY, QuestionDifficulty.EASY],
        Level.TRUNG_BINH: [QuestionDifficulty.EASY, QuestionDifficulty.EASY],
        Level.KHA: [QuestionDifficulty.MEDIUM, QuestionDifficulty.HARD],
        Level.GIOI: [QuestionDifficulty.MEDIUM, QuestionDifficulty.VERY_HARD],
        Level.XUAT_SAC: [QuestionDifficulty.MEDIUM, QuestionDifficulty.VERY_HARD],
    })


@dataclass
class InterviewState:
    candidate_name: str
    profile: str
    level: Level
    topic: str
    current_difficulty: QuestionDifficulty
    attempts_at_current_level: int
    max_attempts_per_level: int
    total_questions_asked: int
    max_total_questions: int
    upper_level_reached: int
    history: List[QuestionAttempt]
    is_finished: bool
    outline: Optional[List[str]] = None
    knowledge_text: Optional[str] = None
    final_score: Optional[float] = None
    created_at: str = field(default_factory=lambda: datetime.datetime.now().isoformat())

    # ‚úÖ NEW FIELDS
    current_phase: InterviewPhase = InterviewPhase.WARMUP  # B·∫Øt ƒë·∫ßu t·ª´ warmup
    warmup_questions_asked: int = 0
    max_warmup_questions: int = 2  # 1-2 c√¢u l√†m quen
    candidate_context: Optional[str] = None  # T√≥m t·∫Øt v·ªÅ th√≠ sinh t·ª´ profile
    outline_summary: Optional[str] = None  # T√≥m t·∫Øt ƒë√°nh gi√° outline t√†i li·ªáu


# =======================
# 2. Utility Functions
# =======================

def classify_level_from_score(score_40: float) -> Level:
    """Ph√¢n lo·∫°i level d·ª±a tr√™n ƒëi·ªÉm 40%"""
    if score_40 < 5.0:
        return Level.YEU
    elif score_40 <= 6.5:
        return Level.TRUNG_BINH
    elif score_40 <= 8.0:
        return Level.KHA
    elif score_40 <= 9.0:
        return Level.GIOI
    else:
        return Level.XUAT_SAC


def get_initial_difficulty(level: Level, config: InterviewConfig) -> QuestionDifficulty:
    """L·∫•y ƒë·ªô kh√≥ ban ƒë·∫ßu cho level"""
    return config.difficulty_map[level][0]


def calculate_question_hash(question: str) -> str:
    """Calculate hash c·ªßa c√¢u h·ªèi ƒë·ªÉ detect duplicate"""
    return hashlib.md5(question.encode()).hexdigest()

import re
import json
import html


def _sanitize_question(q: str) -> str:
    """L√†m s·∫°ch chu·ªói c√¢u h·ªèi kh·ªèi k√Ω t·ª± th·ª´a, d·∫•u s·ªë th·ª© t·ª±, backtick..."""
    s = str(q or "").strip()
    s = re.sub(r'^[`\"]+|[`\"]+$', '', s)
    s = re.sub(r'^\s*"\s*', '', s)
    s = re.sub(r'^\s*\(?\d+\)?[\).\s:-]+\s*', '', s)
    s = s.rstrip(",;}]")
    return s.strip()


def _extract_fallback_question(text: str) -> str:
    """C·ªë g·∫Øng tr√≠ch c√¢u h·ªèi n·∫øu JSON l·ªói."""
    # Th·ª≠ b·∫Øt ƒëo·∫°n "question": "..."
    m = re.search(r'"question"\s*:\s*"([\s\S]+?)"\s*}', text)
    if m:
        return m.group(1)
    # N·∫øu kh√¥ng c√≥, l·∫•y d√≤ng d√†i nh·∫•t
    quoted = re.findall(r'"([^"]{20,})"', text, flags=re.S)
    if quoted:
        return quoted[0]
    lines = [ln.strip() for ln in text.splitlines() if len(ln.strip()) > 30]
    return max(lines, key=len) if lines else text


# def _convert_newlines_to_br(text: str) -> str:
#     """Thay \n th√†nh <br> cho ƒë·ªãnh d·∫°ng hi·ªÉn th·ªã r√µ r√†ng."""
#     text = text.replace("\\n", "\n")
#     text = re.sub(r'\n{2,}', '<br><br>', text)
#     text = re.sub(r'\n', '<br>', text)
#     return text


def _clean_and_parse_json_response(raw_text: str, expected_keys: list[str] = None) -> dict:
    """
    X·ª≠ l√Ω ph·∫£n h·ªìi t·ª´ LLM:
    - ∆Øu ti√™n parse JSON chu·∫©n.
    - N·∫øu l·ªói ‚Üí fallback sang tr√≠ch chu·ªói th·ªß c√¥ng.
    - Gi·ªØ nguy√™n HTML trong <pre><code>.
    """
    if not raw_text:
        return {}

    text = raw_text.strip()

    # 1Ô∏è‚É£ G·ª° code fence n·∫øu c√≥
    if text.startswith("```"):
        text = re.sub(r"^```[a-zA-Z0-9]*\s*", "", text)
        text = text.rstrip("`").strip("`").strip()

    # 2Ô∏è‚É£ L·∫•y ph·∫ßn JSON ch√≠nh
    start, end = text.find("{"), text.rfind("}")
    if start == -1 or end == -1 or end <= start:
        q = _extract_fallback_question(text)
        return {"question": _sanitize_question(q)}

    json_str = text[start:end + 1]

    # 3Ô∏è‚É£ Parse JSON an to√†n
    try:
        parsed = json.loads(json_str)
    except json.JSONDecodeError:
        # Fallback: tr√≠ch chu·ªói "question": "..."
        q = _extract_fallback_question(json_str)
        return {"question": _sanitize_question(q)}
    except Exception as e:
        print("‚ö†Ô∏è L·ªói parse JSON:", e)
        q = _extract_fallback_question(json_str)
        return {"question": _sanitize_question(q)}

    # 4Ô∏è‚É£ Chu·∫©n h√≥a c√¢u h·ªèi
    if isinstance(parsed, dict) and "question" in parsed:
        q = parsed["question"]
        q = _sanitize_question(q)

        return {"question": q}

    # 5Ô∏è‚É£ Fallback cu·ªëi
    q = _extract_fallback_question(text)
    return {"question": _sanitize_question(q)}




# def _clean_and_parse_single_question(raw_text: str, code_snippet: str = None) -> str:
#     """Fallback: parse text th√¥ n·∫øu kh√¥ng c√≥ JSON."""
#     if not raw_text:
#         return ""
#
#     text = raw_text.strip()
#     q = _extract_fallback_question(text)
#     q = html.escape(_sanitize_question(q))
#     q = _convert_newlines_to_br(q)
#
#     if code_snippet:
#         html_snippet = f"<pre><code class='language-java'>{html.escape(code_snippet)}</code></pre>"
#         q += "<br><br>" + html_snippet
#     return q


def _parse_evaluation_response(raw_text: str) -> dict:
    """
    Parse JSON k·∫øt qu·∫£ ch·∫•m ƒëi·ªÉm t·ª´ LLM, v√≠ d·ª•:
    ```json
    {"score": 9.5, "analysis": "Gi·∫£i th√≠ch h·ª£p l√Ω."}
    ```
    """
    if not raw_text:
        return {}

    text = raw_text.strip()

    # Lo·∫°i b·ªè code block (```json ... ```)
    if text.startswith("```"):
        text = re.sub(r"^```[a-zA-Z0-9]*\s*", "", text)
        text = text.rstrip("`").strip("`").strip()

    # T√¨m ƒëo·∫°n JSON trong chu·ªói
    start, end = text.find("{"), text.rfind("}")
    if start != -1 and end != -1:
        json_str = text[start:end+1]
        try:
            return json.loads(json_str)
        except Exception as e:
            print("‚ö†Ô∏è Parse JSON l·ªói:", e)
            return {}

    return {}

# =======================
# 3. Memory Manager
# =======================

class ConversationMemory:
    """Qu·∫£n l√Ω conversation history"""

    def __init__(self, max_turns: int = 6):
        self.memory: List[Dict] = []
        self.max_turns = max_turns

    def add(self, role: str, content: str):
        """Th√™m m·ªôt ƒëo·∫°n h·ªôi tho·∫°i"""
        self.memory.append({"role": role, "content": content})
        self.memory = self.memory[-self.max_turns:]

    def build_prompt(self) -> str:
        """Gh√©p memory th√†nh ƒëo·∫°n h·ªôi tho·∫°i"""
        if not self.memory:
            return ""
        return "\n".join([f"{m['role']}: {m['content']}" for m in self.memory])

    def clear(self):
        """X√≥a memory"""
        self.memory = []


# =======================
# PATCH 3: Th√™m WarmupManager Component
# =======================
# Th√™m sau class ConversationMemory

class WarmupManager:
    """Component qu·∫£n l√Ω giai ƒëo·∫°n warm-up"""

    def __init__(self, llm: GoogleGenerativeAI):
        self.llm = llm

    def generate_warmup_question(
            self,
            candidate_name: str,
            candidate_context: str,
            topic: str,
            warmup_count: int
    ) -> str:
        """
        T·∫°o c√¢u h·ªèi warm-up d·ª±a tr√™n context c·ªßa th√≠ sinh

        Args:
            candidate_name: T√™n th√≠ sinh
            candidate_context: T√≥m t·∫Øt v·ªÅ th√≠ sinh (t·ª´ CV/profile)
            topic: Ch·ªß ƒë·ªÅ ph·ªèng v·∫•n
            warmup_count: C√¢u h·ªèi warm-up th·ª© m·∫•y (0, 1, 2...)
        """

        warmup_templates = {
            0: f"""
B·∫°n l√† interviewer AI th√¢n thi·ªán v√† chuy√™n nghi·ªáp.

TH√îNG TIN TH√ç SINH:
{candidate_context}

H√£y ch√†o h·ªèi v√† gi·ªõi thi·ªáu v·ªÅ bu·ªïi ph·ªèng v·∫•n. Bao g·ªìm:
1. Ch√†o th√≠ sinh b·∫±ng t√™n
2. Gi·ªõi thi·ªáu ch·ªß ƒë·ªÅ: "{topic}"
3. ƒê·∫∑t 1 c√¢u h·ªèi warm-up nh·∫π nh√†ng v·ªÅ kinh nghi·ªám/s·ªü th√≠ch li√™n quan ƒë·∫øn {topic}

Y√äU C·∫¶U:
- Th√¢n thi·ªán, t·∫°o kh√¥ng kh√≠ tho·∫£i m√°i
- C√¢u h·ªèi d·ªÖ tr·∫£ l·ªùi, KH√îNG c·∫ßn ki·∫øn th·ª©c s√¢u
- Gi√∫p th√≠ sinh "l√†m n√≥ng m√°y" tr∆∞·ªõc khi v√†o ph·∫ßn chuy√™n m√¥n

OUTPUT: JSON
{{"question": "l·ªùi ch√†o + c√¢u h·ªèi warm-up"}}
""",
            1: f"""
            B·∫°n l√† interviewer AI th√¢n thi·ªán v√† chuy√™n nghi·ªáp, ƒëang ti·∫øp t·ª•c ph·∫ßn warm-up
            v·ªõi th√≠ sinh {candidate_name}.

            TH√îNG TIN TH√ç SINH:
            {candidate_context}

            C√¢u h·ªèi tr∆∞·ªõc ƒë√£ gi√∫p b·∫°n hi·ªÉu s∆° qua v·ªÅ ·ª©ng vi√™n.
            B√¢y gi·ªù, h√£y ƒë·∫∑t th√™m 1 c√¢u h·ªèi warm-up m·ªõi v·ªÅ:
            - ƒê·ªông l·ª±c h·ªçc {topic}
            - M·ª•c ti√™u ngh·ªÅ nghi·ªáp
            - C√°ch ·ª©ng vi√™n c√≥ th·ªÉ √°p d·ª•ng {topic} trong h·ªçc t·∫≠p ho·∫∑c c√¥ng vi·ªác

            Y√äU C·∫¶U:
            - KH√îNG ch√†o l·∫°i th√≠ sinh (kh√¥ng d√πng "Ch√†o..." ·ªü ƒë·∫ßu)
            - C√≥ th·ªÉ b·∫Øt ƒë·∫ßu b·∫±ng c√¢u chuy·ªÉn ti·∫øp t·ª± nhi√™n, v√≠ d·ª•:
              - "C·∫£m ∆°n chia s·∫ª r·∫•t th√∫ v·ªã c·ªßa b·∫°n, ..."
              - "Nghe th·∫≠t hay, ti·∫øp theo t√¥i mu·ªën h·ªèi th√™m..."
              - "R·∫•t th√∫ v·ªã, v·∫≠y th√¨..."
            - Gi·ªØ gi·ªçng th√¢n thi·ªán, ng·∫Øn g·ªçn, kh√¥ng ƒëi s√¢u k·ªπ thu·∫≠t
            - Kh√¥ng c·∫ßn n√≥i l·∫°i ch·ªß ƒë·ªÅ ho·∫∑c gi·ªõi thi·ªáu ph·ªèng v·∫•n n·ªØa

            OUTPUT: JSON
            {{"question": "c√¢u h·ªèi warm-up th·ª© 2, c√≥ l·ªùi chuy·ªÉn m∆∞·ª£t"}}
            """

        }

        prompt = warmup_templates.get(warmup_count, warmup_templates[1])

        result = self.llm.invoke(prompt)
        parsed = _clean_and_parse_json_response(result)

        return parsed.get("question", f"Xin ch√†o {candidate_name}! B·∫°n ƒë√£ s·∫µn s√†ng cho bu·ªïi ph·ªèng v·∫•n ch∆∞a?")

    def extract_candidate_context(self, profile: str) -> str:
        """
        Tr√≠ch xu·∫•t th√¥ng tin quan tr·ªçng t·ª´ CV/profile ƒë·ªÉ LLM hi·ªÉu v·ªÅ th√≠ sinh

        Returns:
            T√≥m t·∫Øt ng·∫Øn g·ªçn v·ªÅ th√≠ sinh (200-300 t·ª´)
        """
        # B·∫°n c√≥ th·ªÉ d√πng LLM ƒë·ªÉ summarize ho·∫∑c d√πng regex
        # V√≠ d·ª• ƒë∆°n gi·∫£n:
        lines = profile.split('\n')
        summary_lines = []

        keywords = ['t√™n', 'l·ªõp', 'ƒëi·ªÉm', 'k·ªπ nƒÉng', 'd·ª± √°n', 'kinh nghi·ªám', 's·ªü th√≠ch']

        for line in lines[:15]:  # L·∫•y 15 d√≤ng ƒë·∫ßu
            if any(kw in line.lower() for kw in keywords):
                summary_lines.append(line)

        context = '\n'.join(summary_lines[:10])  # Max 10 d√≤ng
        return context if context else profile[:500]  # Fallback: 500 k√Ω t·ª± ƒë·∫ßu


# =======================
# 4. Question Generator
# =======================

class QuestionGenerator:
    """Component chuy√™n generate c√¢u h·ªèi"""
    def __init__(self, llm: GoogleGenerativeAI, config: InterviewConfig):
        self.llm = llm
        self.config = config
        self.asked_questions: set = set()



    def validate_question(self, question: str, topic: str) -> bool:
        """Validate c√¢u h·ªèi c√≥ h·ª£p l·ªá kh√¥ng"""
        if len(question) < 20 or len(question) > 1000:
            return False
        if "Kh√¥ng ƒë·ªß d·ªØ li·ªáu" in question:
            return False
        return True

    def generate_with_context(
            self,
            topic: str,
            difficulty: QuestionDifficulty,
            knowledge_text: str,
            memory: ConversationMemory,
            candidate_context: str,  # ‚úÖ NEW
            context: str = "",outline_summary: str = ""

    ) -> str:
        """
        Generate c√¢u h·ªèi c√≥ nh·∫≠n th·ª©c v·ªÅ th√≠ sinh
        """

        difficulty_descriptions = {
            QuestionDifficulty.VERY_EASY: (
                "r·∫•t c∆° b·∫£n ‚Äì ki·ªÉm tra kh√°i ni·ªám, ƒë·ªãnh nghƒ©a, c√∫ ph√°p ho·∫∑c m·ª•c ƒë√≠ch s·ª≠ d·ª•ng ƒë∆°n gi·∫£n. "
                "C√¢u tr·∫£ l·ªùi ng·∫Øn (1-2 c√¢u)."
            ),
            QuestionDifficulty.EASY: (
                "c∆° b·∫£n ‚Äì y√™u c·∫ßu gi·∫£i th√≠ch kh√°i ni·ªám ho·∫∑c v√≠ d·ª• ƒë∆°n gi·∫£n minh h·ªça c√°ch ho·∫°t ƒë·ªông. "
                "C√≥ th·ªÉ bao g·ªìm m·ªôt ƒëo·∫°n code ng·∫Øn (d∆∞·ªõi 10 d√≤ng) ƒë·ªÉ th√≠ sinh ph√¢n t√≠ch."
            ),
            QuestionDifficulty.MEDIUM: (
                "trung c·∫•p ‚Äì ·ª©ng d·ª•ng th·ª±c t·∫ø, k·∫øt h·ª£p 1‚Äì2 kh√°i ni·ªám ch√≠nh trong c√πng m·ªôt v√≠ d·ª•. "
                "C√¢u tr·∫£ l·ªùi y√™u c·∫ßu ph√¢n t√≠ch ng·∫Øn ho·∫∑c tr√¨nh b√†y code t·∫ßm 15‚Äì25 d√≤ng."
                # "C√≥ th·ªÉ ƒë∆∞a ra 1 ƒëoa code v√† cho th√≠ sinh ph√¢n t√≠ch"
            ),
            QuestionDifficulty.HARD: (
                "n√¢ng cao ‚Äì y√™u c·∫ßu ph√¢n t√≠ch s√¢u ho·∫∑c thi·∫øt k·∫ø m√¥-ƒëun nh·ªè (t·ªëi ƒëa 3 l·ªõp), "
                "k·∫øt h·ª£p 2‚Äì3 nguy√™n l√Ω ho·∫∑c kh√°i ni·ªám ch√≠nh. "
                "Kh√¥ng y√™u c·∫ßu x√¢y d·ª±ng h·ªá th·ªëng ho√†n ch·ªânh. "
                "Code minh h·ªça n√™n n·∫±m trong kho·∫£ng 30‚Äì50 d√≤ng."
            ),
            QuestionDifficulty.VERY_HARD: (
                "r·∫•t kh√≥ ‚Äì y√™u c·∫ßu t·ªïng h·ª£p ki·∫øn th·ª©c ho·∫∑c m√¥ ph·ªèng m·ªôt h·ªá th·ªëng ho√†n ch·ªânh, "
                "√°p d·ª•ng nhi·ªÅu nguy√™n l√Ω c√πng l√∫c , c√≥ t√≠nh m·ªü r·ªông v√† t√°i s·ª≠ d·ª•ng. "
                "ƒê·ªô d√†i code c√≥ th·ªÉ v∆∞·ª£t qu√° 60 d√≤ng v√† mang t√≠nh thi·∫øt k·∫ø th·ª±c t·∫ø."
            )
        }

        history_text = memory.build_prompt()

        prompt = f"""
B·∫°n l√† m·ªôt Interviewer AI TH√îNG MINH v√† C√ì NH·∫¨N TH·ª®C.

TH√îNG TIN TH√ç SINH:
{candidate_context}

L·ªäCH S·ª¨ H·ªòI THO·∫†I:
{history_text}

D·ª±a tr√™n:
1. Background c·ªßa th√≠ sinh
2. C√°ch th√≠ sinh tr·∫£ l·ªùi c√°c c√¢u tr∆∞·ªõc
3. ƒêi·ªÉm m·∫°nh/y·∫øu ƒë√£ th·ªÉ hi·ªán

H√£y t·∫°o c√¢u h·ªèi v·ªÅ "{topic}" v·ªõi ƒë·ªô kh√≥: {difficulty_descriptions[difficulty]}


T√ÄI LI·ªÜU THAM KH·∫¢O:
{knowledge_text if knowledge_text else "Kh√¥ng c√≥ t√†i li·ªáu"}
Tuy nhi√™n, h√£y l∆∞u √Ω b·∫£n t√≥m ·∫Øt t√†i li·ªáu tham kh·∫£o n√†y:
{outline_summary or "Kh√¥ng c√≥ ƒë√°nh gi√° outline"}

‚Üí C·ªë g·∫Øng kh√¥ng h·ªèi qu√° s√¢u v√†o nh·ªØng ph·∫ßn m√† t√†i li·ªáu b·ªã ƒë√°nh gi√° l√† 'thi·∫øu'.

Y√äU C·∫¶U:
- C√¢u h·ªèi C√Å NH√ÇN H√ìA, ph√π h·ª£p v·ªõi level c·ªßa th√≠ sinh
- V·ªõi nh·ªØng c√¢u h·ªèi d·∫°ng l√Ω thuy·∫øt/ kh√°i ni·ªám , ch·ªâ ƒë∆∞a ra c√¢u h·ªèi khi ch·∫Øc ch·∫Øn t√¨m ƒë∆∞·ª£c c√¢u tr·∫£ l·ªùi trong t√†i li·ªáu
- N·∫øu th√≠ sinh y·∫øu ·ªü ƒëi·ªÉm n√†o, c√≥ th·ªÉ h·ªèi l·∫°i theo c√°ch kh√°c
- N·∫øu th√≠ sinh gi·ªèi, ƒë·∫©y kh√≥ h∆°n m·ªôt ch√∫t
- Tham kh·∫£o l·ªãch s·ª≠ ƒë·ªÉ tr√°nh l·∫∑p l·∫°i c√¢u h·ªèi t∆∞∆°ng t·ª±
- N·∫øu th√≠ sinh tr·∫£ l·ªùi t·ªët c√¢u tr∆∞·ªõc, d√†nh 1 l·ªùi khen tr∆∞·ªõc c√¢u h·ªèi m·ªõi.
- Dung l∆∞·ª£ng h·ª£p l√Ω, kh√¥ng qu√° d√†i v√¨ th·ªùi gian ph·ªèng v·∫•n c√≥ h·∫°n:

OUTPUT: JSON
{{"question": " l·ªùi khen (n·∫øu c√≥) + c√¢u h·ªèi c√° nh√¢n h√≥a..."}}
C√°c v√≠ d·ª• code b·∫°n h√£y ƒëƒÉ n√≥ trong th·∫ª <pre><code class='language-java'>...</code></pre> ƒë·ªÉ thu·∫≠n ti·ªán cho m√¨nh render v·ªÅ sau
        D√πng k√Ω t·ª± xu·ªëng d√≤ng <br> ƒë·ªÉ format c√¢u h·ªèi cho d·ªÖ ƒë·ªçc, v√≠ d·ª• code th√¨ d√πng k√Ω t·ª± xu·ªëng d√≤ng nh∆∞ trong ng√¥n ng·ªØ l·∫≠p tr√¨nh'.
        
"""
        print("T·∫°o ra c√¢u h·ªèi v·ªõi ƒë·ªô kh √≥:", difficulty.name)
        result = self.llm.invoke(prompt)
        parsed = _clean_and_parse_json_response(result, ["question"])

        # Format question
        import re
        question = re.sub(
            r"<pre><code([^>]*)>([\s\S]*?)</code></pre>",
            lambda m: f"<pre><code{m.group(1)}>{m.group(2).replace('<br>', '\n')}</code></pre>",
            parsed['question']
        )
        print(f"Final generated question with context: {question}")

        return question
# =======================
# 5. Answer Evaluator
# =======================

class AnswerEvaluator:
    """Component chuy√™n ch·∫•m ƒëi·ªÉm c√¢u tr·∫£ l·ªùi"""

    def __init__(self, llm: GoogleGenerativeAI):
        self.llm = llm

    def evaluate(
            self,
            question: str,
            answer: str,
            knowledge_text: str,
            memory: ConversationMemory,
            topic: str = None,
            difficulty: str = None,
            phase: str = "technical"
    ) -> tuple[float, str]:
        """
        ƒê√°nh gi√° c√¢u tr·∫£ l·ªùi theo 3 l·ªõp logic:
        1Ô∏è‚É£ So kh·ªõp n·ªôi dung c√¢u tr·∫£ l·ªùi v·ªõi t√†i li·ªáu (grounding).
        2Ô∏è‚É£ Ki·ªÉm tra c√°c ph·∫ßn ƒë√∫ng d√π kh√¥ng c√≥ trong t√†i li·ªáu (reasoning m·ªÅm).
        3Ô∏è‚É£ T·ªïng h·ª£p ƒëi·ªÉm v√† ph√¢n t√≠ch.
        """

        history_text = memory.build_prompt()

        prompt = f"""
        B·∫°n l√† gi√°m kh·∫£o ph·ªèng v·∫•n Java, ch·∫•m ƒëi·ªÉm th√≠ sinh d·ª±a tr√™n c·∫£ ƒë·ªô ch√≠nh x√°c k·ªπ thu·∫≠t 
        v√† m·ª©c ƒë·ªô ph√π h·ª£p v·ªõi t√†i li·ªáu tham kh·∫£o.

        B·ªêI C·∫¢NH:
        - Giai ƒëo·∫°n ph·ªèng v·∫•n: {phase}
        - Ch·ªß ƒë·ªÅ: {topic or "Kh√¥ng x√°c ƒë·ªãnh"}
        - M·ª©c ƒë·ªô kh√≥: {difficulty or "Kh√¥ng x√°c ƒë·ªãnh"}

        --- L·ªäCH S·ª¨ H·ªòI THO·∫†I ---
        {history_text}

        --- C√ÇU H·ªéI ---
        {question}

        --- C√ÇU TR·∫¢ L·ªúI ---
        {answer}

        --- T√ÄI LI·ªÜU THAM KH·∫¢O ---
        {knowledge_text if knowledge_text else "Kh√¥ng c√≥ t√†i li·ªáu"}

        H√ÉY TH·ª∞C HI·ªÜN 3 B∆Ø·ªöC:

        1Ô∏è‚É£ **Ph√¢n t√≠ch √Ω ch√≠nh c·ªßa c√¢u tr·∫£ l·ªùi:**
           - Li·ªát k√™ ng·∫Øn g·ªçn c√°c √Ω ch√≠nh m√† th√≠ sinh ƒë√£ n√™u.

        2Ô∏è‚É£ **ƒê·ªëi chi·∫øu t·ª´ng √Ω v·ªõi t√†i li·ªáu:**
           - N·∫øu √Ω c√≥ trong t√†i li·ªáu ho·∫∑c tr√πng kh·ªõp v·ªÅ n·ªôi dung ‚Üí ‚úÖ "Kh·ªõp"
           - N·∫øu √Ω KH√îNG c√≥ trong t√†i li·ªáu nh∆∞ng ƒë√∫ng v√† h·ª£p l√Ω theo ki·∫øn th·ª©c chung ‚Üí ‚öôÔ∏è "ƒê√∫ng ngo√†i t√†i li·ªáu"
           - N·∫øu √Ω sai r√µ r√†ng ho·∫∑c m√¢u thu·∫´n v·ªõi t√†i li·ªáu ‚Üí ‚ùå "Sai"

        3Ô∏è‚É£ **T·ªïng h·ª£p ƒëi·ªÉm v√† nh·∫≠n x√©t:**
           - ‚úÖ Kh·ªõp nhi·ªÅu: 8‚Äì10 ƒëi·ªÉm
           - ‚öôÔ∏è ƒê√∫ng ngo√†i t√†i li·ªáu: 6‚Äì8 ƒëi·ªÉm
           - ‚ùå Sai ho·∫∑c l·ªách: 0‚Äì4 ƒëi·ªÉm
           - N·∫øu t√†i li·ªáu kh√¥ng ƒë·ªß th√¥ng tin ƒë·ªÉ ƒë√°nh gi√°: 5 ƒëi·ªÉm, ghi "T√†i li·ªáu kh√¥ng ƒë·ªß".

        TR·∫¢ V·ªÄ D·ªÆ LI·ªÜU D∆Ø·ªöI D·∫†NG JSON:
        {{
          "score": <s·ªë nguy√™n ho·∫∑c float t·ª´ 0-10>,
          "analysis": "<ph√¢n t√≠ch ng·∫Øn g·ªçn v·ªÅ c√°c √Ω ch√≠nh, ch·ªâ ra ph·∫ßn n√†o kh·ªõp v√† ph·∫ßn n√†o kh√¥ng>"
        }}
        """

        try:
            result = self.llm.invoke(prompt)
            parsed = _parse_evaluation_response(result)
            # print("Raw evaluation response:", result)
            # print("Parsed evaluation:", parsed)

            score = float(parsed.get("score", 5.0))
            analysis = parsed.get("analysis", "Kh√¥ng c√≥ nh·∫≠n x√©t")

            print(f"üìä Ch·∫•m ƒëi·ªÉm: {score}, Nh·∫≠n x√©t: {analysis}")

            # C·∫≠p nh·∫≠t v√†o memory
            memory.add("student", answer)
            memory.add("interviewer", f"üìä ƒêi·ªÉm: {score}/10 - {analysis}")

            return score, analysis

        except Exception as e:
            print(f"L·ªói khi ch·∫•m ƒëi·ªÉm: {e}")
            return 5.0, "L·ªói khi ch·∫•m ƒëi·ªÉm, m·∫∑c ƒë·ªãnh 5/10"


# =======================
# 6. Difficulty Adapter
# =======================

class DifficultyAdapter:
    """Component ƒëi·ªÅu ch·ªânh ƒë·ªô kh√≥"""

    def __init__(self, config: InterviewConfig):
        self.config = config

    def decide_next_action(self, score: float) -> str:
        """Quy·∫øt ƒë·ªãnh action ti·∫øp theo"""
        if score >= self.config.threshold_high:
            return "harder"
        elif score >= self.config.threshold_low:
            return "same"
        else:
            return "easier"

    def get_next_difficulty(
            self,
            current: QuestionDifficulty,
            action: str
    ) -> QuestionDifficulty:
        """T√≠nh ƒë·ªô kh√≥ ti·∫øp theo"""
        difficulties = list(QuestionDifficulty)
        current_idx = difficulties.index(current)

        if action == "harder" and current_idx < len(difficulties) - 1:
            return difficulties[current_idx + 1]
        elif action == "easier" and current_idx > 0:
            return difficulties[current_idx - 1]
        else:
            return current


# =======================
# 7. Session Manager
# =======================

class SessionManager:
    """Component qu·∫£n l√Ω sessions v√† persistence"""

    def __init__(self, mongo_uri: str = "mongodb://localhost:27017/"):
        self.client = MongoClient(mongo_uri)
        self.db = self.client["interviewer_ai"]
        self.collection = self.db["interview_sessions"]
        self.sessions: Dict[str, InterviewState] = {}

    def create_session(self, state: InterviewState) -> str:
        """T·∫°o session m·ªõi"""
        self.sessions[state.candidate_name] = state
        return state.candidate_name

    def get_session(self, candidate_name: str) -> Optional[InterviewState]:
        """L·∫•y session"""
        return self.sessions.get(candidate_name)

    def save_session(self, candidate_name: str) -> str:
        """L∆∞u session v√†o MongoDB"""
        state = self.sessions.get(candidate_name)
        if not state:
            raise ValueError(f"Session not found: {candidate_name}")

        # B·ªè knowledge_text v√¨ qu√° d√†i
        state.knowledge_text = ""

        # Convert state to dict
        state_dict = asdict(state)

        # Convert Enum fields
        state_dict['level'] = state.level.value
        state_dict['current_difficulty'] = state.current_difficulty.value

        for attempt in state_dict.get('history', []):
            if isinstance(attempt.get('difficulty'), Enum):
                attempt['difficulty'] = attempt['difficulty'].value

        # T·∫°o document ƒë·ªÉ l∆∞u
        session_data = {
            "state": state_dict,
            "timestamp": datetime.datetime.utcnow(),
            "status": "active" if not state.is_finished else "completed"
        }

        # Fix Enum cho current_phase n·∫øu c√≥
        if isinstance(session_data["state"].get("current_phase"), Enum):
            session_data["state"]["current_phase"] = session_data["state"]["current_phase"].value

        # Th·ª±c hi·ªán l∆∞u v√†o MongoDB
        result = self.collection.insert_one(session_data)
        return str(result.inserted_id)

    def resume_session(self, session_id: str) -> InterviewState:
        """Kh√¥i ph·ª•c session t·ª´ MongoDB"""
        session = self.collection.find_one({"_id": ObjectId(session_id)})
        if not session:
            raise ValueError(f"Session not found in DB: {session_id}")

        state_dict = session["state"]
        # Reconstruct enums
        state_dict["level"] = Level(state_dict["level"])
        state_dict["current_difficulty"] = QuestionDifficulty(state_dict["current_difficulty"])

        # Reconstruct history
        history = []
        for attempt in state_dict["history"]:
            attempt["difficulty"] = QuestionDifficulty(attempt["difficulty"])
            history.append(QuestionAttempt(**attempt))
        state_dict["history"] = history

        state = InterviewState(**state_dict)
        self.sessions[state.candidate_name] = state

        return state

    def delete_session(self, candidate_name: str):
        """X√≥a session"""
        self.sessions.pop(candidate_name, None)


# =======================
# 8. Knowledge Builder
# =======================

class KnowledgeBuilder:
    """Component x√¢y d·ª±ng knowledge context"""

    def __init__(self, knowledge_db: Optional[FAISS] = None):
        self.knowledge_db = knowledge_db
        self.retriever = None
        if knowledge_db:
            self.retriever = knowledge_db.as_retriever(search_kwargs={"k": 5})

    @property
    def knowledge_db(self):
        return self._knowledge_db

    @knowledge_db.setter
    def knowledge_db(self, value):
        self._knowledge_db = value
        if value:
            self.retriever = value.as_retriever(search_kwargs={"k": 5})
            print("üîÑ retriever auto-updated from new knowledge_db")
        else:
            self.retriever = None
            print("‚ö†Ô∏è retriever cleared (knowledge_db=None)")
    def build_context(
            self,
            topic: str,
            outline: Optional[List[str]] = None
    ) -> str:
        """X√¢y d·ª±ng knowledge context"""
        results = []

        if outline and len(outline) > 0:
            for item in outline:
                query = f"{topic} {item}"
                docs = self.retriever.invoke(query)
                results.extend(docs)
        else:
            docs = self.retriever.invoke(topic)
            results.extend(docs)

        # Lo·∫°i tr√πng l·∫∑p
        seen = set()
        unique_docs = []
        for doc in results:
            if doc.page_content not in seen:
                seen.add(doc.page_content)
                unique_docs.append(doc)

        return "\n\n".join([doc.page_content for doc in unique_docs])


# =======================
# 9. Adaptive Interviewer (Orchestrator)
# =======================

class AdaptiveInterviewer:
    """Main orchestrator - ph·ªëi h·ª£p c√°c components"""

    def __init__(
            self,

            api_key: str = None,
            config: InterviewConfig = None,
            embeddings_model: str = "intfloat/multilingual-e5-large-instruct",
            llm_model: str = "gemini-2.5-flash",
            mongo_uri: str = "mongodb://localhost:27017/",
        device: str = "cpu"  # ‚úÖ TH√äM PARAMETER M·ªöI
    ):
        # Load API key
        self.api_key = api_key or loadapi()
        self.config = config or InterviewConfig()

        # ‚úÖ Initialize embeddings with device control
        self.embeddings = HuggingFaceEmbeddings(
            model_name=embeddings_model,
            model_kwargs={'device': device},
            encode_kwargs={'device': device}
        )
        # Load vector stores
        # self.cv_db = FAISS.load_local(
        #     cv_vectorstore_path,
        #     self.embeddings,
        #     allow_dangerous_deserialization=True
        # )
        self.cv_db=None
        # knowledge_db = FAISS.load_local(
        #     knowledge_vectorstore_path,
        #     self.embeddings,
        #     allow_dangerous_deserialization=True
        # )
        knowledge_db=None

        # Initialize LLM
        self.llm = GoogleGenerativeAI(
            model=llm_model,
            google_api_key=self.api_key,
            temperature=self.config.llm_temperature
        )

        # Initialize components
        self.question_generator = QuestionGenerator(self.llm, self.config)
        self.answer_evaluator = AnswerEvaluator(self.llm)
        self.difficulty_adapter = DifficultyAdapter(self.config)
        self.session_manager = SessionManager(mongo_uri)
        self.knowledge_builder = KnowledgeBuilder(knowledge_db)

        # Memory per session
        self.memories: Dict[str, ConversationMemory] = {}
        # ‚úÖ NEW: Initialize WarmupManager
        self.warmup_manager = WarmupManager(self.llm)

    def _get_or_create_memory(self, candidate_name: str) -> ConversationMemory:
        """L·∫•y ho·∫∑c t·∫°o memory cho candidate"""
        if candidate_name not in self.memories:
            self.memories[candidate_name] = ConversationMemory(
                max_turns=self.config.max_memory_turns
            )
        return self.memories[candidate_name]

    def load_candidate_profile(self, candidate_name: str) -> tuple[str, Level]:
        """Load h·ªì s∆° v√† ph√¢n lo·∫°i level"""
        profile_docs = self.cv_db.similarity_search(candidate_name, k=1)
        if not profile_docs:
            raise ValueError(f"Kh√¥ng t√¨m th·∫•y h·ªì s∆° cho {candidate_name}")

        profile_content = profile_docs[0].page_content
        print("Loaded profile content:", profile_content)

        score_match = re.search(r'ƒêi·ªÉm 40%[:\s]+([0-9.]+)', profile_content)
        if score_match:
            score_40 = float(score_match.group(1))
            level = classify_level_from_score(score_40)
        else:
            level = Level.TRUNG_BINH  # Default

        return profile_content, level

    def start_interview(
            self,
            candidate_name: str,
            topic: str,
            outline: Optional[List[str]] = None,
            knowledge_text: Optional[str] = None,
            outline_summary=""
    ) -> Dict:
        """B·∫Øt ƒë·∫ßu ph·ªèng v·∫•n t·ª´ giai ƒëo·∫°n WARMUP"""

        # Load profile
        profile, level = self.load_candidate_profile(candidate_name)
        initial_difficulty = get_initial_difficulty(level, self.config)

        # ‚úÖ Extract candidate context
        candidate_context = self.warmup_manager.extract_candidate_context(profile)

        # Build knowledge n·∫øu ch∆∞a c√≥
        if not knowledge_text:
            knowledge_text = self.knowledge_builder.build_context(topic, outline)

        # ‚úÖ Create state v·ªõi WARMUP phase
        state = InterviewState(
            candidate_name=candidate_name,
            profile=profile,
            level=level,
            topic=topic,
            current_difficulty=initial_difficulty,
            attempts_at_current_level=0,
            max_attempts_per_level=self.config.max_attempts_per_level,
            total_questions_asked=0,
            max_total_questions=self.config.max_total_questions,
            upper_level_reached=0,
            history=[],
            is_finished=False,
            outline=outline,
            knowledge_text=knowledge_text,
            current_phase=InterviewPhase.WARMUP,  # ‚úÖ Start with warmup
            warmup_questions_asked=0,
            candidate_context=candidate_context , # ‚úÖ Save context
            outline_summary=outline_summary
        )

        self.session_manager.create_session(state)
        memory = self._get_or_create_memory(candidate_name)

        # ‚úÖ Generate WARMUP question
        question = self.warmup_manager.generate_warmup_question(
            candidate_name=candidate_name.split(',')[0],  # L·∫•y t√™n
            candidate_context=candidate_context,
            topic=topic,
            warmup_count=0
        )

        # Add to history (kh√¥ng ch·∫•m ƒëi·ªÉm)
        state.history.append(QuestionAttempt(
            question=question,
            answer="",
            score=0.0,  # Warmup kh√¥ng c√≥ ƒëi·ªÉm
            analysis="(warmup - kh√¥ng ch·∫•m ƒëi·ªÉm)",
            difficulty=QuestionDifficulty.VERY_EASY,
            timestamp=datetime.datetime.now().isoformat(),
            question_hash=calculate_question_hash(question)
        ))

        return {
            "candidate": candidate_name,
            "topic": topic,
            "profile": profile,
            "level": level.value,
            "question": question,
            "difficulty": "warmup",  # ‚úÖ ƒê√°nh d·∫•u l√† warmup
            "phase": "warmup"
        }

    def submit_answer(self, candidate_name: str, answer: str) -> Dict:
        """Submit c√¢u tr·∫£ l·ªùi - x·ª≠ l√Ω theo phase"""

        state = self.session_manager.get_session(candidate_name)
        if not state:
            return {"error": "Interview not started"}

        if not state.history:
            return {"error": "No question found"}

        last_attempt = state.history[-1]
        memory = self._get_or_create_memory(candidate_name)

        # ‚úÖ X·ª≠ l√Ω theo phase
        if state.current_phase == InterviewPhase.WARMUP:
            return self._handle_warmup_answer(state, answer, memory)
        elif state.current_phase == InterviewPhase.TECHNICAL:
            return self._handle_technical_answer(state, answer, memory)
        else:  # CLOSING
            return self._handle_closing(state)

    def _handle_warmup_answer(
            self,
            state: InterviewState,
            answer: str,
            memory: ConversationMemory
    ) -> Dict:
        """X·ª≠ l√Ω c√¢u tr·∫£ l·ªùi warmup (KH√îNG ch·∫•m ƒëi·ªÉm)"""

        last_attempt = state.history[-1]

        # L∆∞u c√¢u tr·∫£ l·ªùi (kh√¥ng ch·∫•m ƒëi·ªÉm)
        last_attempt.answer = answer
        last_attempt.score = 0.0
        last_attempt.analysis = "‚úÖ C·∫£m ∆°n b·∫°n ƒë√£ chia s·∫ª!"

        # L∆∞u v√†o memory
        memory.add("student", answer)
        memory.add("interviewer", "C·∫£m ∆°n b·∫°n! ")

        state.warmup_questions_asked += 1

        # ‚úÖ Check xem ƒë√£ ƒë·ªß warmup ch∆∞a
        if state.warmup_questions_asked >= state.max_warmup_questions:
            # Chuy·ªÉn sang TECHNICAL phase
            state.current_phase = InterviewPhase.TECHNICAL

            # Generate c√¢u h·ªèi technical ƒë·∫ßu ti√™n
            next_question = self.question_generator.generate_with_context(
                state.topic,
                state.current_difficulty,
                state.knowledge_text,
                memory,
                state.candidate_context,  # ‚úÖ Pass context


                "B·∫Øt ƒë·∫ßu ph·∫ßn chuy√™n m√¥n",
                outline_summary=state.outline_summary,
            )

            state.history.append(QuestionAttempt(
                question=next_question,
                answer="",
                score=0.0,
                analysis="(pending)",
                difficulty=state.current_difficulty,
                timestamp=datetime.datetime.now().isoformat(),
                question_hash=calculate_question_hash(next_question)
            ))

            return {
                "finished": False,
                "score": 0,
                "analysis": "‚úÖ Ph·∫ßn l√†m quen ho√†n t·∫•t! B√¢y gi·ªù ch√∫ng ta b·∫Øt ƒë·∫ßu ph·∫ßn chuy√™n m√¥n nh√©.",
                "next_question": next_question,
                "difficulty": state.current_difficulty.value,
                "phase": "technical"  # ‚úÖ Chuy·ªÉn phase
            }
        else:
            # Generate c√¢u warmup ti·∫øp theo
            next_warmup = self.warmup_manager.generate_warmup_question(
                candidate_name=state.candidate_name.split(',')[0],
                candidate_context=state.candidate_context,
                topic=state.topic,
                warmup_count=state.warmup_questions_asked
            )

            state.history.append(QuestionAttempt(
                question=next_warmup,
                answer="",
                score=0.0,
                analysis="(warmup)",
                difficulty=QuestionDifficulty.VERY_EASY,
                timestamp=datetime.datetime.now().isoformat(),
                question_hash=calculate_question_hash(next_warmup)
            ))

            return {
                "finished": False,
                "score": 0,
                "analysis": "‚úÖ Tuy·ªát v·ªùi!",
                "next_question": next_warmup,
                "difficulty": "warmup",
                "phase": "warmup"
            }

    def _handle_technical_answer(
            self,
            state: InterviewState,
            answer: str,
            memory: ConversationMemory
    ) -> Dict:
        """X·ª≠ l√Ω c√¢u tr·∫£ l·ªùi technical (C√ì ch·∫•m ƒëi·ªÉm) - GI·ªêNG CODE C≈®"""

        last_attempt = state.history[-1]

        # Evaluate answer
        score, analysis = self.answer_evaluator.evaluate(
            last_attempt.question,
            answer,
            state.knowledge_text,
            memory
        )
        # print(f"Evaluated score: {score}, analysis: {analysis}")

        # Update attempt
        last_attempt.answer = answer
        last_attempt.score = score
        last_attempt.analysis = analysis

        # Update state
        self._update_state(state, score)

        # Check if finished
        if state.is_finished:
            summary = self._generate_summary(state)
            self.session_manager.save_session(state.candidate_name)

            return {"finished": True, "summary": summary}

        # Generate next technical question v·ªõi context
        next_question = self.question_generator.generate_with_context(
            state.topic,
            state.current_difficulty,
            state.knowledge_text,
            memory,
            state.candidate_context,  # ‚úÖ Context-aware
            f"ƒê√£ h·ªèi {state.total_questions_asked} c√¢u",
            outline_summary=state.outline_summary,
        )

        state.history.append(QuestionAttempt(
            question=next_question,
            answer="",
            score=0.0,
            analysis="(pending)",
            difficulty=state.current_difficulty,
            timestamp=datetime.datetime.now().isoformat(),
            question_hash=calculate_question_hash(next_question)
        ))

        return {
            "finished": False,
            "score": score,
            "analysis": analysis,
            "next_question": next_question,
            "difficulty": state.current_difficulty.value,
            "phase": "technical"
        }

    def _handle_closing(self, state: InterviewState) -> Dict:
        """X·ª≠ l√Ω k·∫øt th√∫c ph·ªèng v·∫•n"""
        summary = self._generate_summary(state)
        self.session_manager.save_session(state.candidate_name)
        return {"finished": True, "summary": summary}

    def _update_state(self, state: InterviewState, score: float):
        """Update state sau m·ªói c√¢u h·ªèi"""
        state.total_questions_asked += 1

        action = self.difficulty_adapter.decide_next_action(score)

        if action == "harder":
            state.upper_level_reached += 1
            if state.upper_level_reached <= self.config.max_upper_level:
                state.current_difficulty = self.difficulty_adapter.get_next_difficulty(
                    state.current_difficulty, "harder"
                )
                state.attempts_at_current_level = 0
            else:
                state.is_finished = True

        elif action == "same":
            state.attempts_at_current_level += 1

        else:  # easier
            state.current_difficulty = self.difficulty_adapter.get_next_difficulty(
                state.current_difficulty, "easier"
            )
            state.attempts_at_current_level += 1
            state.upper_level_reached = max(0, state.upper_level_reached - 1)

        # Check termination
        if (state.attempts_at_current_level >= state.max_attempts_per_level or
                state.total_questions_asked >= state.max_total_questions or
                state.is_finished):
            state.is_finished = True
            scores = [a.score for a in state.history if a.score > 0]
            state.final_score = sum(scores) / len(scores) if scores else 0.0

    def _generate_summary(self, state: InterviewState) -> Dict:
        """Generate final summary"""
        return {
            "candidate_info": {
                "name": state.candidate_name,
                "profile": state.profile,
                "classified_level": state.level.value
            },
            "interview_stats": {
                "timestamp": datetime.datetime.now().isoformat(),
                "total_questions": len(state.history),
                "final_score": state.final_score,
                "topic": state.topic,
                "outline": state.outline
            },
            "question_history": [
                {
                    "question_number": i,
                    "difficulty": attempt.difficulty.value,
                    "question": attempt.question,
                    "answer": attempt.answer,
                    "score": attempt.score,
                    "analysis": attempt.analysis
                }
                for i, attempt in enumerate(state.history, 1)
            ]
        }


# =======================
# 10. Usage Example
# =======================

if __name__ == "__main__":
    # Custom config
    custom_config = InterviewConfig(
        threshold_high=7.5,
        threshold_low=4.5,
        max_total_questions=10,
        llm_temperature=0.6
    )

    # Initialize interviewer
    interviewer = AdaptiveInterviewer(
        cv_vectorstore_path="NotUse/vector_db_csv",
        knowledge_vectorstore_path="NotUse/vector_db2chunk_nltk",
        config=custom_config
    )

    # Start interview
    result = interviewer.start_interview(
        candidate_name="Ng√¥ VƒÉn Ph√°t,KT1",
        topic="Ki·ªÉu d·ªØ li·ªáu trong Java",
        outline=["Ki·ªÉu d·ªØ l·ªáu c∆° s·ªü", "Ki·ªÉu d·ªØ li·ªáu g√≥i", "Chu·ªói k√Ω t·ª± String"]
    )

    print("Started interview:", result)